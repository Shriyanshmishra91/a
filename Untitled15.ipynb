{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4CnkFN3sMihW4Y+/J5oMD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shriyanshmishra91/a/blob/main/Untitled15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ny3a9OkOw5Ft"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdf187ab"
      },
      "source": [
        "Ques1 what s a DecisonTree and how doesits work theconxet of classfication ?\n",
        "\n",
        "Ans Adecision tree isa suprivsed learning aloogrthim used for classfication regression tasks it works it works in by recurisly partinting the data  into small subsets based on the features oe tje input data based on data the trres rprespentiont the base logical of the feature or attribute and edges  which rprsent the possible based on mesure impurioty such asgini impulity  proccess continous  until stopping  ceretion entropy the prtocess  isa rechead a minium number  of sample at anode .\n",
        "\n",
        "Ques 2 Explain  the concpet of gini impurity and entorpy are two common measure  how does impacact the splites  in decision  tress.?\n",
        "\n",
        "Ans 2\n",
        "\n",
        "GiniImpurtity : measures the problatilty is mis classflying  asample at node it is caculated as the sum of the squred problites of each class  at node Alower giri impurity valve indicates a more homogenous node.\n",
        "\n",
        "Entorphy mesure the amount  of uncertainty  or randomes in data set  at anode  it ius caculted asthe  sum of probilatilty of eaches  class at the node multipled by the logartihm of the probability .a lower entorpy  valve indicates node.\n",
        "\n",
        "Ques3 what is differnce  between pre prunning and post pruning in decision tree ?give one  prtical   advantage of using each .\n",
        "\n",
        "Ans  pre pruning and post puring are two techniques used to prvent overtfitting in decision tress\n",
        "\n",
        "PRE-PURING:THE thechniques stops the from growing fruther once a cretain cinditions is met suchas aminium number condition  is met suchas aminium  and maxium depth the prtical advantge of pre puring is that it reduces computational cost by stopping the tree growing uncessarily.\n",
        "\n",
        "POST-PURING This technique  purnse the tree after it has been fully grown . the partical advantages of post pruning is that it can be sginficantiy to he prductively power of the tree imporving is interpetabitly .\n",
        "\n",
        "Quse4  what is innformation gain in decision trees and why is it is imprtotant for computing resources inculding gpu and tpus ?\n",
        "\n",
        "Ans Information gain iuisameasure of how much a feture reduces uncernatily in targets  vriblkev .it isculated as differnce and after  unceytancticy   inenporty before and after splitting the databasedon feature .information gain is imprtant for computing resources because its helps decision tree to:\n",
        "\n",
        "Qus5 What are some common real-world applications of Decision Trees, and what are their main advantages and limitation?\n",
        "\n",
        "Ans\n",
        "Decision Trees are widely used in various fields for both classification and regression tasks. Some common applications include:\n",
        "\n",
        "*   **Medical Diagnosis:** Helping to diagnose diseases based on symptoms and patient data.\n",
        "*   **Credit Risk Assessment:** Determining the creditworthiness of loan applicants.\n",
        "*   **Customer Relationship Management (CRM):** Analyzing customer behavior to predict churn or identify potential leads.\n",
        "*   **Financial Analysis:** Predicting stock prices or identifying fraudulent transactions.\n",
        "*   **Manufacturing and Quality Control:** Identifying defects in products based on various parameters.\n",
        "*   **Natural Language Processing (NLP):** Used in tasks like sentiment analysis or text classification.\n",
        "\n",
        "**Main Advantages:**\n",
        "\n",
        "*   **Easy to Understand and Interpret:** The tree structure is intuitive and easy to visualize, making it easy to understand how decisions are made.\n",
        "*   **Handles Both Numerical and Categorical Data:** Decision Trees can work with both types of data without requiring extensive data preprocessing.\n",
        "*   **Requires Little Data Preparation:** Unlike some other algorithms, Decision Trees do not require feature scaling or normalization.\n",
        "*   **Can Model Non-Linear Relationships:** They can capture complex interactions between features.\n",
        "\n",
        "**Limitations:**\n",
        "\n",
        "*   **Prone to Overfitting:** Decision Trees can easily overfit the training data, especially with complex trees. Pruning techniques are often used to mitigate this.\n",
        "*   **Sensitive to Small Variations in Data:** A small change in the data can lead to a completely different tree structure.\n",
        "*   **Bias Towards Features with More Levels:** When dealing with categorical features with many levels, Decision Trees can be biased towards selecting those features.\n",
        "*   **Can Create Complex Trees:** With many features, the tree can become very complex and difficult to interpret.\n",
        "*   **Limited to Axis-Parallel Splits:** Decision Trees make decisions based on splitting the data along axes, which may not be optimal for all types of data distributi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ques6\n",
        "#Write a Python program to:\n",
        "# Load the Iris Dataset\n",
        "# Train a Decision Tree Classifier using the Gini criterion\n",
        "# Print the model’s accuracy and feature importances\n",
        "#(Include your Python code and output in the code box below.)\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier using the Gini criterion\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Print feature importances\n",
        "print(\"Feature Importances:\")\n",
        "for name, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f\"- {name}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2iCZYY4-Qbp",
        "outputId": "4af0795d-3506-48bf-d71c-e4d858d768c7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n",
            "Feature Importances:\n",
            "- sepal length (cm): 0.0000\n",
            "- sepal width (cm): 0.0191\n",
            "- petal length (cm): 0.8933\n",
            "- petal width (cm): 0.0876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Qustion7\n",
        "#write a Python program to:\n",
        "# Load the Iris Dataset\n",
        "# Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to a fully-grown tree.\n",
        "#(Include your Python code and output in the code box below.)\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier with max_depth=3\n",
        "clf_limited = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
        "clf_limited.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set with limited depth tree\n",
        "y_pred_limited = clf_limited.predict(X_test)\n",
        "\n",
        "# Print the model's accuracy for limited depth tree\n",
        "accuracy_limited = accuracy_score(y_test, y_pred_limited)\n",
        "print(f\"Model Accuracy (max_depth=3): {accuracy_limited:.2f}\")\n",
        "\n",
        "# Train a fully-grown Decision Tree Classifier\n",
        "clf_full = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set with fully-grown tree\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "\n",
        "# Print the model's accuracy for fully-grown tree\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "print(f\"Model Accuracy (fully grown): {accuracy_full:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHi3IF_i_XBY",
        "outputId": "5670d1e3-c5eb-4d41-fb31-36e4688facb8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy (max_depth=3): 1.00\n",
            "Model Accuracy (fully grown): 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Write a Python program to:\n",
        "# Load the California Housing Dataset\n",
        "# Train a Decision Tree Regressor\n",
        "# Print the Mean Squared Error (MSE) and feature importances\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "california_housing = fetch_california_housing()\n",
        "X = california_housing.data\n",
        "y = california_housing.target\n",
        "feature_names = california_housing.feature_names\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Print the Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "\n",
        "# Print feature importances\n",
        "print(\"Feature Importances:\")\n",
        "for name, importance in zip(feature_names, regressor.feature_importances_):\n",
        "    print(f\"- {name}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTt0Ao6i_wH5",
        "outputId": "23ef116f-73ca-471d-8428-032a9414bca7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.53\n",
            "Feature Importances:\n",
            "- MedInc: 0.5235\n",
            "- HouseAge: 0.0521\n",
            "- AveRooms: 0.0494\n",
            "- AveBedrms: 0.0250\n",
            "- Population: 0.0322\n",
            "- AveOccup: 0.1390\n",
            "- Latitude: 0.0900\n",
            "- Longitude: 0.0888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#question9 write to program as python\n",
        "#loaddatahouseset\n",
        "#Tune the Decision Tree’s max_depth and min_samples_split using GridSearchCV\n",
        "#Print the best parameters and the resulting model accuracy\n",
        "#(Include your Python code and output in the code box below.)\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [None, 3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Create a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the resulting model accuracy\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "best_clf = grid_search.best_estimator_\n",
        "y_pred = best_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with best parameters: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2uG59c2A_ey",
        "outputId": "10dd78f3-d6e1-4adb-823b-98b37f20f551"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': None, 'min_samples_split': 10}\n",
            "Model Accuracy with best parameters: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values. Explain the step-by-step process you would follow to:\n",
        "● Handle the missing values\n",
        "● Encode the categorical features\n",
        "● Train a Decision Tree model\n",
        "● Tune its hyperparameters\n",
        "● Evaluate its performance And describe what business value this model could provide in the real-world setting.\n",
        "\n",
        "Answer:\n",
        " solve this problem, follow these steps:\n",
        "\n",
        "1. Handle Missing Values: Use mean/median imputation or interpolation to fill missing values.\n",
        "2. Encode Categorical Features: Apply one-hot encoding or label encoding to convert categorical features into numerical values.\n",
        "3. Split Data: Divide the dataset into training (70%) and testing sets (30%).\n",
        "4. Train Decision Tree Model: Use the training set to train a Decision Tree Classifier.\n",
        "5. Tune Hyperparameters: Perform grid search to find optimal hyperparameters like max_depth and min_samples_split.\n",
        "6. Evaluate Model: Assess the model's performance using metrics like accuracy, precision, recall, F1-score, and ROC-AUC on the testing set.\n",
        "\n",
        "By following these steps, you can develop a predictive model that accurately identifies patients with a certain disease."
      ],
      "metadata": {
        "id": "NRj7qtm0BgbJ"
      }
    }
  ]
}